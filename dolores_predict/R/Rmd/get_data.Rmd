---
title: "get_data_tests"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(RNRCS)
##library(fable)
library(readr)
library(lubridate)
options(scipen = 999)
```

## Get snotel data
```{r}
meta_data<-grabNRCS.meta(ntwrks = c("SNTL", "SNTLT", "SCAN"))

dolores_sites<-meta_data[[1]]%>%
  as_tibble()%>%
  filter(state =="CO", str_detect(huc, "140300"))%>%
  mutate(site_id_num = as.numeric(str_match_all(site_id, "[0-9]+")))

dolores_site_ids<-dolores_sites%>%
  pull(site_id_num)%>%
  unlist()%>%
  as.numeric()
```


```{r}
data_test<-grabNRCS.data(network = "SNTL", 
              site_id = 1185, 
              timescale = "daily", 
              DayBgn = '1985-01-01',
              DayEnd = Sys.Date()
)%>%as_tibble()

get_snotl_data<-function(site_id){
  grabNRCS.data(network = "SNTL", 
              site_id = site_id, 
              timescale = "daily", 
              DayBgn = '1985-01-01',
              DayEnd = Sys.Date()
              )%>%
    as_tibble()%>%
    mutate(site_id_num = site_id)
}

all_sntl_data<-lapply(dolores_site_ids, get_snotl_data)%>%
  bind_rows()

se_site<-all_sntl_data%>%
  left_join(select(dolores_sites, site_id_num, site_id), by= "site_id_num")%>%
  select(Date, Snow.Depth..in..Start.of.Day.Values, Snow.Water.Equivalent..in..Start.of.Day.Values, site_id_num, site_id)%>%
  mutate(
    Date = as.Date(Date),
    Year = year(Date)
    )%>%
  rename(snow_depth = 2, snow_water_eq=3)%>%
  group_by(year(Date), site_id_num)%>%
  summarize(max_se = max(snow_water_eq, na.rm = T))%>%
  ungroup()%>%
  rename(year=1)

avg_snwater_eq<-se_site%>%
  filter(year>1986&site_id_num %in% c(465, 586, 589, 739))%>%
  group_by(year)%>%
  summarize(avg_snow_water_e = mean(max_se))
  
  
```

## BOR Data
```{r}
bor_meta<-grabNRCS.meta(ntwrks = c("BOR"))[[1]]%>%
  as_tibble()

bor_meta%>%
  filter(str_detect(county, "Montezuma"))%>%
  select(site_id, site_name)


bor_data<-grabBOR.data(site_id = "MPHC2000", 
                       timescale = 'daily', 
                       DayBgn = '1985-01-01',
                        DayEnd = Sys.Date())%>%
  as_tibble()%>%
  mutate(ds = as.Date(Date),
         y = as.numeric(`Reservoir Storage Volume (ac_ft) Start of Day Values`))%>%
  select(ds, y)

bor_data%>%
  tail()

bor_data%>%
  rename(volume = 2)%>%
  mutate(Date = as.Date(Date), volume = as.numeric(volume), year = year(Date))%>%
  ggplot(aes(yday(Date), volume, color = as.factor(year)))+
  geom_line()+
  theme_light()
```


Building forcasting model
```{r}
train<-bor_data%>%
  filter(year(ds)!=1985, year(ds)<2018)
  
test<-bor_data%>%
  filter(year(ds)>=2018)

prophet_model_test<-prophet(
  train,
  growth = "linear",
  yearly.seasonality = TRUE
)

forcast_test<-predict(prophet_model_test, test)

forcast_test %>%
  mutate(resid = trend - yhat) %>%
  ggplot(aes(x = ds, y = resid)) +
    geom_hline(yintercept = 0, color = "red") +
    geom_point(alpha = 0.5, color = "black") +
    geom_smooth() +
    theme_light()

```

```{r}
library(fable)

bor_ts<-bor_data%>%
  filter(year(ds)>1987 & year(ds)<2019)%>%
  drop_na(y)%>%
  as_tsibble()
  

bor_ts%>%
  filter(is.na(y))

fit<-bor_ts%>%
  fill_gaps(.full = TRUE)%>%
  model(
    snaive = SNAIVE(y ~ lag("year")),
    nnetar = NNETAR(y, n_networks = 20)
  )

fc <- fit %>%
  forecast(h = "3 years")
fc

fc%>%
  autoplot(bor_ts, level = NULL)
```


figuring out timeseries
```{r}
tbl1 <- tibble(
  date = as.Date("2017-01-01") + 0:9,
  value = rnorm(10)
)

as_tsibble(tbl1, index = date)
```

ETS Forecasting

```{r}
bor_data<-grabBOR.data(site_id = "MPHC2000", 
                       timescale = 'daily', 
                       DayBgn = '1985-01-01',
                        DayEnd = Sys.Date())%>%
  as_tibble()%>%
  mutate(date = as.Date(Date),
         res_volume = as.numeric(`Reservoir Storage Volume (ac_ft) Start of Day Values`))%>%
  select(date, res_volume)

bor_data%>%
  mutate(res_volume = ifelse(is.na(res_volume), lag(res_volume), res_volume))%>%
  filter(is.na(res_volume)) 

bor_data%>%
  rename(date = 1, vol = 2)%>%
  filter(year)



bor_data_ts<-bor_data%>%
  mutate(res_volume = ifelse(is.na(res_volume), lag(res_volume), res_volume))%>%
  filter(year(date)>1987)%>%
  as_tsibble(index = date)


# fit<-bor_data_ts%>%
#   model(
#         arima = ARIMA(res_volume~)
#   )

report(fit)

fc<-fit%>%
  forecast(h = "3 years")

fc%>%
  autoplot(bor_data_ts, level = 80, alpha = 0.5)
```

```{r}
flow_data<-read_tsv("https://waterservices.usgs.gov/nwis/dv/?format=rdb&sites=09169500,%2009166500&startDT=1985-02-01&endDT=2020-02-07&statCd=00003&siteType=ST&siteStatus=all", skip = 35)%>%
  select(2:5)%>%
  rename(site_id = 1, date = 2, flow=3, code = 4)%>%
  mutate(site_id = ifelse(site_id == "09166500", "Dolores", "Bedrock"))%>%
  drop_na()

bedrock_flow<-flow_data%>%
  filter(site_id == "Bedrock"& year(date)>1986)

bedrock_flow%>%
  ggplot(aes(date, flow))+
  geom_line()

bedrock_flow%>%
  group_by(year(date), month(date))%>%
  filter(flow>1000)%>%
  summarize(max = max(flow), count = n())%>%
  ungroup()%>%
  filter(max>1000)%>%
  View()

predicted_variable<-bedrock_flow%>%
  filter(flow>1000 & month(date) %in% c(3:6))%>%
  count(year(date))%>%
  rename(year = 1, raftable_releases = 2)
```

new BOR data
```{r}
bor_data<-grabBOR.data(site_id = "MPHC2000", 
                       timescale = 'daily', 
                       DayBgn = '1985-01-01',
                        DayEnd = Sys.Date())%>%
  as_tibble()%>%
  mutate(date = as.Date(Date),
         res_volume = as.numeric(`Reservoir Storage Volume (ac_ft) Start of Day Values`))%>%
  select(date, res_volume)

bor_data%>%
  mutate(res_volume = ifelse(is.na(res_volume), lag(res_volume), res_volume))%>%
  filter(is.na(res_volume)) 

res_vol<-bor_data%>%
  filter(month(date) %in% c(12, 01, 02))%>%
  group_by(year(date))%>%
  summarize(avg_vol = min(res_volume, na.rm = T))%>%
  ungroup()%>%
  rename(year = 1)%>%
  filter(year>1986)
```

```{r}
var_df<-predicted_variable%>%
  full_join(avg_snwater_eq)%>%
  full_join(res_vol)%>%
  mutate(raftable_releases = ifelse(is.na(raftable_releases), 0, raftable_releases))

var_df_train<-var_df%>%
  filter(year!=2020)

var_df%>%
  filter(avg_vol<240000)

var_df%>%
  ggplot(aes(raftable_releases, avg_snow_water_e, size = avg_vol))+
  geom_point()
```

```{r}
library(caret)
set.seed(1234)

control <- trainControl(method="repeatedcv", number=10, repeats=3, search = "random")

rf_default <- train(raftable_releases~avg_snow_water_e+avg_vol, 
                    data=var_df_train, 
                    method="rf", 
                    tuneLength=3,
                    ntree = 1000,
                    trControl=control)

var_df_train%>%
  mutate(prediction = stats::predict(rf_default, .))%>%
  ggplot(aes(raftable_releases, prediction))+
  geom_point()+
  geom_text(aes(label=year),hjust=0, vjust=0)

var_df%>%
  filter(year==2020)%>%
  mutate(prediction = predict(rf_default, .))

stats::predict(rf_default, var_df)

?predict()
```

xgboos
```{r}
ctrl <- trainControl(method = "cv", 
                     number = 5)

xgbGrid <- expand.grid(nrounds = c(100,200),  # this is n_estimators in the python code above
                       max_depth = 2,
                       colsample_bytree = seq(0.5, 0.9, length.out = 5),
                       ## The values below are default values in the sklearn-api. 
                       mtry =3,
                       eta = 0.1,
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )

xgb_model <- train(raftable_releases~avg_snow_water_e+avg_vol,
                  data=var_df,
                  tuneGrid = xgbGrid,
                  trControl = ctrl)
```







